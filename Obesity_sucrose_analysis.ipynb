{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## code was written using Python 2.7.13 ##\n",
    "import os\n",
    "import matplotlib.pyplot as plt  #v1.5.1\n",
    "%matplotlib inline\n",
    "import seaborn as sns #v0.7.1\n",
    "import numpy as np #v1.14.4\n",
    "import scipy.stats as stats #v0.19.0\n",
    "from sklearn.decomposition import PCA\n",
    "from os import listdir\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd #0.23.0\n",
    "import sklearn #0.18.1\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##EDIT THIS SECTION.\n",
    "\n",
    "%cd 'C:\\Users\\Stuber Lab\\Desktop\\Raw data\\obesity imaging\\'\n",
    "\n",
    "colors = ['g','darkorange']\n",
    "\n",
    "## normalize data by baseline?\n",
    "normalize_on=['yes']\n",
    "baseline=[20,35]\n",
    "test=[35,50]\n",
    "\n",
    "## Save Figures?\n",
    "save_figs=['no']\n",
    "\n",
    "## Save files?\n",
    "save_files=['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def analyze_obesity(basedir1,basedir2,condition1,condition2,filename):\n",
    "    condition=[condition1]+[condition2]\n",
    "    maxnumneurons = 1000 #just used to initialize arrays. Should be larger than the total number of neurons\n",
    "    maxframes=2000\n",
    "    framerate=5\n",
    "    maxtrials=10    #number of trials\n",
    "    framespertrial=70\n",
    "    numpreframes=35\n",
    "\n",
    "    ## Load files in basedir1 and basedir2\n",
    "    def load_files(directory):\n",
    "        signals_pop = np.nan*np.zeros((maxtrials,framespertrial,maxnumneurons))\n",
    "        data_dirs = os.walk(directory).next()[1]\n",
    "        numneuronstillnow = 0\n",
    "        for data_dir in data_dirs:\n",
    "            signals=np.load(os.path.join(directory,data_dir,'lick_align.npy'))\n",
    "            numneurons=signals.shape[2]\n",
    "            numframes=signals.shape[1]\n",
    "            numtrials=signals.shape[0]\n",
    "            for a in range(0,numneurons):\n",
    "                signals_pop[0:numtrials,0:signals.shape[1],numneuronstillnow+a]=signals[0:maxtrials,:,a]\n",
    "            numneuronstillnow += numneurons\n",
    "        extractedsignals=signals_pop[:,:,:numneuronstillnow]\n",
    "        print 'files = '+str(data_dirs)\n",
    "        print '\\nNumber of neurons = '+str(extractedsignals.shape[2])\n",
    "        return extractedsignals,numneuronstillnow,numframes,numneurons,numtrials\n",
    "    extractedsignals1,numneuronstillnow1,numframes1,numneurons1,numtrials1=load_files(basedir1)\n",
    "    extractedsignals2,numneuronstillnow2,numframes2,numneurons2,numtrials2=load_files(basedir2)\n",
    "\n",
    "    #normalize data by baseline period\n",
    "    if normalize_on[0]=='yes':\n",
    "        def normalize_data(data):\n",
    "            BLnorm=np.nan*np.zeros((data.shape))\n",
    "            BLavg=np.nan*np.zeros((data.shape[0],data.shape[2]))\n",
    "            for b in range(0,data.shape[2]):\n",
    "                for a in range(0,data.shape[0]):\n",
    "                    BLavg[a,b]=np.nanmean(data[a,baseline[0]:baseline[1],b])\n",
    "            for e in range(0,data.shape[2]):\n",
    "                for d in range(0,data.shape[1]):\n",
    "                    for c in range(0,data.shape[0]):\n",
    "                        BLnorm[c,d,e]=data[c,d,e]-BLavg[c,e]\n",
    "            reshape_response=BLnorm\n",
    "            return reshape_response\n",
    "        extractedsignals1_norm=normalize_data(extractedsignals1)\n",
    "        extractedsignals2_norm=normalize_data(extractedsignals2)\n",
    "    else:\n",
    "        extractedsignals1_norm=extractedsignals1\n",
    "        extractedsignals2_norm=extractedsignals2\n",
    "\n",
    "    avg_response1=np.nanmean(extractedsignals1_norm,axis=0)\n",
    "    avg_response2=np.nanmean(extractedsignals2_norm,axis=0)\n",
    "    peak_response1=np.nanmax(avg_response1[test[0]:test[1],:],axis=0)\n",
    "    peak_response2=np.nanmax(avg_response2[test[0]:test[1],:],axis=0)\n",
    "    avg_rew_response1=np.nanmean(avg_response1[test[0]:test[1],:],axis=0)\n",
    "    avg_rew_response2=np.nanmean(avg_response2[test[0]:test[1],:],axis=0)\n",
    "    #remove frames preceding start of baseline window\n",
    "    avg_response1=avg_response1[baseline[0]:,:]\n",
    "    avg_response2=avg_response2[baseline[0]:,:]\n",
    "    framespertrial=framespertrial-baseline[0]\n",
    "    if save_files[0]=='yes':\n",
    "        np.savetxt(filename+'_avg_response_'+condition[0]+'.csv',avg_rew_response1.T,delimiter=',')\n",
    "        np.savetxt(filename+'_avg_response_'+condition[1]+'.csv',avg_rew_response2.T,delimiter=',')\n",
    "\n",
    "    ##combine arrays for bar plots\n",
    "    def combine_arrays(data1,data2):\n",
    "        max_events=[data1.shape[0],data2.shape[0]]\n",
    "        max_events=np.max(max_events)\n",
    "        combined_array=np.nan*np.zeros((max_events,2))\n",
    "        combined_array[:data1.shape[0],0]=data1\n",
    "        combined_array[:data2.shape[0],1]=data2\n",
    "        return combined_array\n",
    "    peak_amp_combined=combine_arrays(peak_response1,peak_response2)\n",
    "    avg_response_combined=combine_arrays(avg_rew_response1,avg_rew_response2)\n",
    "\n",
    "    def bar_plot(data,ytitle,ylim):\n",
    "        data1=data[:,0];data1=data1[~np.isnan(data1)]\n",
    "        data2=data[:,1];data2=data2[~np.isnan(data2)]\n",
    "        means=np.nanmean(data[:,:],axis=0)\n",
    "        sems=np.nan*np.zeros((1,2))\n",
    "        sems[:,0]=stats.sem(data1,axis=0)\n",
    "        sems[:,1]=stats.sem(data2,axis=0)\n",
    "        sems=np.squeeze(sems)\n",
    "        ind = (0,.5)\n",
    "        width = 0.4\n",
    "        fig_sig1,ax=plt.subplots(1,figsize=(3,6))\n",
    "        bar=ax.bar(ind,means,width,yerr=sems,color=colors,error_kw={'ecolor':'black','linewidth':2})\n",
    "        ax.set_ylabel(ytitle)\n",
    "        ax.legend((bar[0],bar[1]),(condition[0],condition[1]),loc=[1,.5])\n",
    "        ax.set_axis_bgcolor('white')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([1,1.1,1.2])\n",
    "        ax.set_ylim(ylim[0],ylim[1])\n",
    "        if save_figs[0]=='yes':\n",
    "            fig_sig1.savefig((filename+'_'+ytitle+'_AVG_bar'+'.png'), format='png',bbox_inches='tight')\n",
    "        plt.show()\n",
    "    fig3=bar_plot(avg_response_combined,'Avg amplitude',[0,.10])\n",
    "\n",
    "    ymin=-.05\n",
    "    ymax=.15\n",
    "    sns.set(font_scale=1.5)\n",
    "    fig1,ax = plt.subplots(1)\n",
    "    sns.tsplot(avg_response1.T,color=colors[0], condition=condition[0]+' (n = '+str(extractedsignals1.shape[2])+')', legend=True)\n",
    "    sns.tsplot(avg_response2.T,color=colors[1], condition=condition[1]+' (n = '+str(extractedsignals2.shape[2])+')', legend=True)\n",
    "    ax.set_title('Avg response',fontsize='16')\n",
    "    ax.set_xlabel('Time from lick (s)',fontsize='16')\n",
    "    ax.set_ylabel('delta F',fontsize='16')\n",
    "    ax.set_axis_bgcolor('white')\n",
    "    # ax.set_yticks([1,1.1,1.2])\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xticks(range(5, framespertrial+1, 10))\n",
    "    ax.set_xticklabels([str(((a-(numpreframes-baseline[0])+5)/framerate)) for a in range(0, framespertrial+1, 10)],fontsize='16')\n",
    "    ax.plot([numpreframes-baseline[0], numpreframes-baseline[0]], [ymin, ymax], '--k', linewidth=1)\n",
    "    ax.plot([0, framespertrial], [1, 1], '--k', linewidth=1)\n",
    "    if save_figs[0]=='yes':\n",
    "        plt.savefig((filename+'_pop_response_overlay'+'.pdf'), format='pdf')\n",
    "        plt.savefig((filename+'_pop_response_overlay'+'.png'), format='png')\n",
    "        plt.show()\n",
    "\n",
    "    #plot population heatmaps sorted\n",
    "    sortneurons1 = np.argsort(np.nanmean(avg_response1[numpreframes-baseline[0]:(numpreframes-baseline[0])+(test[1]-test[0]),:],axis=0))\n",
    "    sortneurons2 = np.argsort(np.nanmean(avg_response2[numpreframes-baseline[0]:(numpreframes-baseline[0])+(test[1]-test[0]),:],axis=0))\n",
    "    fig4 = plt.figure(4)\n",
    "    ax = plt.subplot(121)\n",
    "    sns.heatmap(avg_response1[:,sortneurons1].T, cmap=plt.get_cmap('coolwarm'), vmin=-.2, vmax=.2,linewidth=0)\n",
    "    ax.set_title(filename+' '+str(condition[0]), fontsize=16)\n",
    "    ax.set_xlabel('Time from lick (s)', fontsize=14, labelpad=-1)\n",
    "    ax.set_xticks(range(5, framespertrial+1, 10))\n",
    "    ax.set_xticklabels([str(((a-(numpreframes-baseline[0])+5)/framerate)) for a in range(0, framespertrial+1, 10)],fontsize='16')\n",
    "    ax.plot([numpreframes-baseline[0], numpreframes-baseline[0]], [0, extractedsignals1.shape[2]], '--k', linewidth=1)\n",
    "    ax.set_yticks(range(0, extractedsignals1.shape[2], 100))\n",
    "    ax.set_yticklabels([str(a) for a in range(0,extractedsignals1.shape[2],100)],fontsize='14')\n",
    "    plt.xticks(fontsize='14')\n",
    "    plt.yticks(fontsize='14')\n",
    "    plt.ylabel('ROIs', fontsize='16')\n",
    "    fig4.tight_layout(w_pad=5)\n",
    "\n",
    "    fig5 = plt.figure(4)\n",
    "    ax = plt.subplot(122)\n",
    "    sns.heatmap(avg_response2[:,sortneurons2].T, cmap=plt.get_cmap('coolwarm'), vmin=-.2, vmax=.2,linewidth=0)\n",
    "    ax.set_title(filename+' '+str(condition[1]), fontsize=16)\n",
    "    ax.set_xlabel('Time from lick (s)', fontsize=14, labelpad=-1)\n",
    "    ax.set_xticks(range(5, framespertrial+1, 10))\n",
    "    ax.set_xticklabels([str(((a-(numpreframes-baseline[0])+5)/framerate)) for a in range(0, framespertrial+1, 10)],fontsize='16')\n",
    "    ax.plot([numpreframes-baseline[0], numpreframes-baseline[0]], [0, extractedsignals2.shape[2]], '--k', linewidth=1)\n",
    "    ax.set_yticks(range(0, extractedsignals1.shape[2], 100))\n",
    "    ax.set_yticklabels([str(a) for a in range(0,extractedsignals2.shape[2],100)],fontsize='14')\n",
    "    plt.xticks(fontsize='14')\n",
    "    plt.yticks(fontsize='14')\n",
    "    plt.ylabel('ROIs', fontsize='16')\n",
    "    fig5.tight_layout(w_pad=5)\n",
    "    if save_figs[0]=='yes':\n",
    "        plt.savefig(filename+'_heatmap_sorted.pdf', format='pdf')\n",
    "        plt.show()\n",
    "    return avg_rew_response1,avg_rew_response2,peak_response1,peak_response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot data for 0 week condition ##\n",
    "basedir1 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry all neurons\\\\10suc\\\\Pre\\\\control-pre'\n",
    "basedir2 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry all neurons\\\\10suc\\\\Pre\\\\high fat-pre'\n",
    "condition1='control'\n",
    "condition2='high fat'\n",
    "filename='CvHF_0weeks_TEST'\n",
    "C_0wk_avg,HF_0wk_avg,C_0wk_peak,HF_0wk_peak=analyze_obesity(basedir1=basedir1,basedir2=basedir2,condition1=condition1,condition2=condition2,filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot data for 2 week condition ##\n",
    "basedir1 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry all neurons\\\\10suc\\\\2wks\\\\control 2wks'\n",
    "basedir2 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry all neurons\\\\10suc\\\\2wks\\\\HF 2wks'\n",
    "condition1='control'\n",
    "condition2='high fat'\n",
    "filename='CvHF_2weeks_TEST'\n",
    "C_2wk_avg,HF_2wk_avg,C_2wk_peak,HF_2wk_peak=analyze_obesity(basedir1=basedir1,basedir2=basedir2,condition1=condition1,condition2=condition2,filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot data for 0 week condition ##\n",
    "basedir1 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry all neurons\\\\10suc\\\\12wks\\\\control 12wks'\n",
    "basedir2 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry all neurons\\\\10suc\\\\12wks\\\\HF 12wks'\n",
    "condition1='control'\n",
    "condition2='high fat'\n",
    "filename='CvHF_12weeks_TEST'\n",
    "C_12wk_avg,HF_12wk_avg,C_12wk_peak,HF_12wk_peak=analyze_obesity(basedir1=basedir1,basedir2=basedir2,condition1=condition1,condition2=condition2,filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Use SVM to classify data based on 'group' (Fig. 2f) ##\n",
    "\n",
    "## create dataframes for SVM ##\n",
    "##group1=high fat; group0=control\n",
    "def create_df(avg,peak,group,timepoint):\n",
    "    df=pd.DataFrame()\n",
    "    df['avg']=avg\n",
    "    df['peak']=peak\n",
    "    df['group']=group\n",
    "    df['timepoint']=timepoint\n",
    "    return df\n",
    "df_C0H=create_df(C_0wk_avg,C_0wk_peak,0,0)\n",
    "df_HF0H=create_df(HF_0wk_avg,HF_0wk_peak,1,0)\n",
    "df_C2H=create_df(C_2wk_avg,C_2wk_peak,0,2)\n",
    "df_HF2H=create_df(HF_2wk_avg,HF_2wk_peak,1,2)\n",
    "df_C12H=create_df(C_12wk_avg,C_12wk_peak,0,12)\n",
    "df_HF12H=create_df(HF_12wk_avg,HF_12wk_peak,1,12)\n",
    "frames = [df_HF0H,df_HF2H,df_C2H,df_C12H,df_HF12H]\n",
    "df=pd.concat(frames)\n",
    "df=df_C0H.append(frames,ignore_index=True)\n",
    "df=df.dropna(axis=0)\n",
    "dfreduced=df.dropna(axis=0)\n",
    "df_norm=dfreduced\n",
    "\n",
    "### EDIT THIS to restrict timepoint  ###\n",
    "timepoint=0 ## either 0, 2, or 12 \n",
    "df_norm=df_norm[(df_norm['timepoint']==timepoint)]\n",
    "predict_outcome='group'  #which parameter do you want to predict (values should be 0 or 1)\n",
    "print df_norm.shape\n",
    "svm_filename='Sucrose_0wks_pred_group'\n",
    "iterations=1000 #Define number of iterations\n",
    "test_data=.1  #defines split for test/train sets\n",
    "test=[35,50]\n",
    "### End Edit ###\n",
    "\n",
    "df=df_norm\n",
    "parameters = [{'C': [0.001, .01,.1,1,10,100,1000], 'kernel': ['linear']},\n",
    "              {'C': [0.001, .01,.1,1,10,100,1000], 'gamma': [0.001, .01,.1,1,10,100,1000], 'kernel': ['rbf']}]\n",
    "pred_score=np.nan*np.zeros((iterations))\n",
    "rand_score=np.nan*np.zeros((iterations))\n",
    "for i in range(iterations):\n",
    "    ##randomly subset df into test and train sets\n",
    "    msk = np.random.rand(len(df))>test_data\n",
    "    train = df[msk]\n",
    "    clf = GridSearchCV(SVC(), parameters,cv=10)\n",
    "    train_labels=train[[predict_outcome]].values\n",
    "    c,r=train_labels.shape\n",
    "    train_labels=train_labels.reshape(c,)\n",
    "    clf.fit(train[['avg','peak']], train_labels)\n",
    "    print ('prediction accuracy = ', clf.best_score_)\n",
    "    pred_score[i]=(clf.best_score_)*100\n",
    "    ##random array of 1s and 0s for shuffled classifier\n",
    "    rand_group=pd.DataFrame(np.random.randint(2,size=train.shape[0]))\n",
    "    clf.fit(train[['avg','peak']], rand_group[0])\n",
    "    print ('shuffled accuracy = ', clf.best_score_)\n",
    "    rand_score[i]=(clf.best_score_)*100\n",
    "    print i\n",
    "\n",
    "d,p=stats.ks_2samp(pred_score,rand_score)\n",
    "plt.figure(figsize=(5,5))\n",
    "ax=plt.subplot(111)\n",
    "n = np.arange(1,len(pred_score)+1) / np.float(len(pred_score))\n",
    "Xs = np.sort(pred_score)\n",
    "plt.step(Xs,n,color='g',label='Model prediction',alpha=0.7,linewidth=2)\n",
    "n2= np.arange(1,len(rand_score)+1) / np.float(len(rand_score))\n",
    "Xs2= np.sort(rand_score)\n",
    "plt.step(Xs2,n,color='r',label='Random',alpha=0.7,linewidth=2)\n",
    "\n",
    "ax.set_axis_bgcolor('white')\n",
    "plt.xlabel('Prediction accuracy %',fontsize=14)\n",
    "plt.ylabel('Proportion of runs',fontsize=14)\n",
    "plt.title('K-S test Results: '+str(\"D={0:.7f}\".format(round(d,3)))+' , '+str(\"p={0:.7f}\".format(round(p,3))),fontsize=12)\n",
    "plt.legend(fontsize=14,loc=2)\n",
    "plt.savefig(str(iterations)+str('iter_')+str(test_data)+str(timepoint)+'wks_test_data_prediction_accuracy_hist.pdf')\n",
    "np.savetxt(svm_filename+str(iterations)+'iterations_'+str(test_data)+'_'+str(timepoint)+'wks_split_prediction_accuracy.csv',pred_score,delimiter=',')\n",
    "np.savetxt(svm_filename+str(iterations)+'iterations_'+str(test_data)+'_'+str(timepoint)+'wks_split_RANDOM_prediction_accuracy.csv',rand_score,delimiter=',')\n",
    "plt.show()\n",
    "\n",
    "print np.nanmean(pred_score)\n",
    "print np.nanmean(rand_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot data for 0 week condition TRACKED CELLS##\n",
    "basedir1 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry tracked\\\\sucrose responses\\\\Pre\\\\control-pre'\n",
    "basedir2 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry tracked\\\\sucrose responses\\\\Pre\\\\high fat-pre'\n",
    "condition1='control'\n",
    "condition2='high fat'\n",
    "filename='CvHF_TRACKED_0weeks_TEST'\n",
    "C_0wk_tracked,HF_0wk_tracked=analyze_obesity(basedir1=basedir1,basedir2=basedir2,condition1=condition1,condition2=condition2,filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot data for 2 week condition TRACKED CELLS##\n",
    "basedir1 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry tracked\\\\sucrose responses\\\\2wks\\\\control 2wks'\n",
    "basedir2 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry tracked\\\\sucrose responses\\\\2wks\\\\HF 2wks'\n",
    "condition1='control'\n",
    "condition2='high fat'\n",
    "filename='CvHF_TRACKED_2weeks_TEST'\n",
    "C_2wk_tracked,HF_2wk_tracked=analyze_obesity(basedir1=basedir1,basedir2=basedir2,condition1=condition1,condition2=condition2,filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot data for 2 week condition TRACKED CELLS##\n",
    "basedir1 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry tracked\\\\sucrose responses\\\\12wks\\\\control 12wks'\n",
    "basedir2 = '\\\\Users\\\\Stuber Lab\\\\Desktop\\\\Raw data\\\\obesity imaging\\\\hungry tracked\\\\sucrose responses\\\\12wks\\\\HF 12wks'\n",
    "condition1='control'\n",
    "condition2='high fat'\n",
    "filename='CvHF_TRACKED_12weeks_TEST'\n",
    "C_12wk_tracked,HF_12wk_tracked=analyze_obesity(basedir1=basedir1,basedir2=basedir2,condition1=condition1,condition2=condition2,filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## compare tracked cells (Fig. 2h) ##\n",
    "sns.set_style('whitegrid')\n",
    "fig10 = plt.figure(figsize=(10,10))\n",
    "ax=sns.regplot(C_0wk_tracked,C_2wk_tracked,scatter=True,color='forestgreen',ci=None, scatter_kws={'s':100},line_kws={'linestyle':'dashed'},label='C_0wk_vs_2wk')\n",
    "ax=sns.regplot(C_0wk_tracked,C_12wk_tracked,scatter=True,color='darkgreen',ci=None,marker='s', scatter_kws={'s':100},label='C_0wk_vs_12wk')\n",
    "ax=sns.regplot(HF_0wk_tracked,HF_2wk_tracked,scatter=True,color='orange',ci=None, scatter_kws={'s':100},line_kws={'linestyle':'dashed'},label='HF_0wk_vs_2wk')\n",
    "ax=sns.regplot(HF_0wk_tracked,HF_12wk_tracked,scatter=True,color='darkorange',ci=None,marker='s', scatter_kws={'s':100},label='HF_0wk_vs_12wk')\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## normalize sucrose responses by 0 week condition and plot bars (Fig. S3g) ##\n",
    "C_0wk_tracked_norm=(C_0wk_tracked/float(np.nanmean(C_0wk_tracked)))*100\n",
    "C_2wk_tracked_norm=(C_2wk_tracked/float(np.nanmean(C_0wk_tracked)))*100\n",
    "C_12wk_tracked_norm=(C_12wk_tracked/float(np.nanmean(C_0wk_tracked)))*100\n",
    "HF_0wk_tracked_norm=(HF_0wk_tracked/float(np.nanmean(HF_0wk_tracked)))*100\n",
    "HF_2wk_tracked_norm=(HF_2wk_tracked/float(np.nanmean(HF_0wk_tracked)))*100\n",
    "HF_12wk_tracked_norm=(HF_12wk_tracked/float(np.nanmean(HF_0wk_tracked)))*100\n",
    "\n",
    "## manually calculate means and sems to go into bar plot ##\n",
    "means=np.nan*np.zeros((2,3))\n",
    "sem=np.nan*np.zeros((2,3))\n",
    "sem[0,0]=stats.sem(C_0wk_tracked_norm,ddof=0)\n",
    "sem[0,1]=stats.sem(C_2wk_tracked_norm,ddof=0)\n",
    "sem[0,2]=stats.sem(C_12wk_tracked_norm,ddof=0)\n",
    "sem[1,0]=stats.sem(HF_0wk_tracked_norm,ddof=0)\n",
    "sem[1,1]=stats.sem(HF_2wk_tracked_norm,ddof=0)\n",
    "sem[1,2]=stats.sem(HF_12wk_tracked_norm,ddof=0)\n",
    "means[0,0]= C_0wk_tracked_norm.mean()\n",
    "means[0,1]= C_2wk_tracked_norm.mean()\n",
    "means[0,2]= C_12wk_tracked_norm.mean()\n",
    "means[1,0]= HF_0wk_tracked_norm.mean()\n",
    "means[1,1]= HF_2wk_tracked_norm.mean()\n",
    "means[1,2]= HF_12wk_tracked_norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot bars for Fig. S8g ##\n",
    "ind = (0,1,2)\n",
    "ind2=(0.4,1.4,2.4)\n",
    "width = 0.4\n",
    "ylim=[0,150]\n",
    "fig_tracked_bars,ax=plt.subplots(1,figsize=(3,6))\n",
    "plt.bar=ax.bar(ind,means[0,:],width,yerr=sem[0,:],color='g',error_kw={'ecolor':'black','linewidth':2})\n",
    "plt.bar1=ax.bar(ind2,means[1,:],width,yerr=sem[1,:],color='darkorange',error_kw={'ecolor':'black','linewidth':2})\n",
    "ax.legend((bar[0],bar1[1]),(condition[0],condition[1]),loc=[1,.5],fontsize=20)\n",
    "ax.set_axis_bgcolor('white')\n",
    "plt.xticks((0,1.2,2.2),(0,2,12),fontsize=20)\n",
    "plt.xlabel('Weeks',fontsize=20)\n",
    "plt.ylabel('Normalized response (%BL)',fontsize=20)\n",
    "plt.yticks((0,50,100,150),fontsize=20)\n",
    "ax.set_ylim(ylim[0],ylim[1])\n",
    "if save_figs[0]=='yes':\n",
    "    fig_tracked_bars.savefig((filename+'_TRACKED_amplitude_AVG_bar.png'), format='png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
